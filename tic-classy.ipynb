{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "In this notebook, we will explore the process of classifying Tumor Immune cells data using **QuPID** vectorization and a Vanilla Random Forest Classifier. The main steps include:\n",
    "\n",
    "\n",
    "1. *Data Processing*: Preparing the data by computing persistent diagrams for $H_0$ and $H_1$ for each sample.\n",
    "2. *Diagrams Embedding*: Each diagram from the dataset is embedded in a vector space using QuPID.\n",
    "3. *Model Training and Evaluation*: Building and training a RandomForest classifier and assess the model's performance across different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import qupid.utils as spu\n",
    "from qupid.qupid import QuPID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "Here, we prepare the generated data for analysis by computing persistent diagrams for $H_0$ and $H_1$ homology groups for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_CD68 = 73\n",
    "n_FoxP3 = 74\n",
    "n_CD8 = 65\n",
    "\n",
    "#CD68 -> 73\n",
    "samplesCD68 = []\n",
    "for i in range(n_CD68):\n",
    "    df = pd.read_csv(f\"./data/TIC+/TumourT_CCD6810NNCodensitySample{i+1}RipsMax1.txt\",  skiprows=4, sep=\" \", header=None, usecols=[0, 1]).to_numpy()\n",
    "    samplesCD68.append(df)\n",
    "\n",
    "#FoxP3->74\n",
    "samplesFoxP3 = []\n",
    "for i in range(n_FoxP3):\n",
    "    df = pd.read_csv(f\"./data/TIC+/TumourT_CFoxP310NNCodensitySample{i+1}RipsMax1.txt\",  skiprows=4, sep=\" \", header=None, usecols=[0, 1]).to_numpy()\n",
    "    samplesFoxP3.append(df)\n",
    "\n",
    "#CD8->65\n",
    "samplesCD8 = []\n",
    "for i in range(n_CD8):\n",
    "    df = pd.read_csv(f\"./data/TIC+/TumourT_CCD810NNCodensitySample{i+1}RipsMax1.txt\",  skiprows=4, sep=\" \", header=None, usecols=[0, 1]).to_numpy()\n",
    "    samplesCD8.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence computed for CD68\n",
      "Persistence computed for CD8\n",
      "Persistence computed for FoxP3\n"
     ]
    }
   ],
   "source": [
    "spu.compute_tic_ph(\"CD68\", samplesCD68)\n",
    "spu.compute_tic_ph(\"CD8\", samplesCD8)\n",
    "spu.compute_tic_ph(\"FoxP3\", samplesFoxP3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagrams Embedding\n",
    "In this step, each persistence diagram from the dataset is embedded in a vector space using the **QuPID** vectorization method. This transformation facilitates the application of machine learning algorithms by representing the complex topological data in a more accessible form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams_dicts = {\n",
    "    \"CD68\": spu.get_tic_data(\"CD68\"),\n",
    "    \"CD8\": spu.get_tic_data(\"CD8\"),\n",
    "    \"FoxP3\": spu.get_tic_data(\"FoxP3\")\n",
    "}\n",
    "\n",
    "samples_dict, H0_min, H0_max, H1_min, H1_max = spu.process_tic_dataset(diagrams_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = \"wvt\"\n",
    "wave = \"coif1\"\n",
    "r = 20\n",
    "\n",
    "# Initialize QuPID models\n",
    "modelH0 = QuPID(function=function, resolution=(1, r), global_max=H0_max, global_min=H0_min, wave=wave, alpha=(0, 1e3))\n",
    "modelH1 = QuPID(function=function, resolution=(r, r), global_max=H1_max, global_min=H1_min, wave=wave, alpha=(1e3, 5e3))\n",
    "\n",
    "# Fit and transform data\n",
    "transformed_data = {category: [] for category in samples_dict}\n",
    "for category, (samples_H0, samples_H1) in samples_dict.items():\n",
    "    for i in range(len(samples_H0)):\n",
    "        modelH0.fit([samples_H0[i]])\n",
    "        modelH1.fit([samples_H1[i]])\n",
    "        transformed_data[category].append(np.concatenate((modelH0.transform(samples_H0[i]), modelH1.transform(samples_H1[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation \n",
    "In this section, we focus on both building and evaluating our classifier. Initially, we train the classifier using the processed data. Subsequently, we assess its performance by evaluating its accuracy and reliability in classifying different types of orbits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy over 20 runs for 3way: 0.7848837209302325\n",
      "Mean Accuracy over 20 runs for CD68 vs CD8: 0.7125\n",
      "Mean Accuracy over 20 runs for CD8 vs FoxP3: 0.9089285714285713\n",
      "Mean Accuracy over 20 runs for CD68 vs FoxP3: 0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "n_runs = 20\n",
    "mean_accuracy_3way = spu.evaluate_classifier_tic(transformed_data, \"3way\", n_runs)\n",
    "mean_accuracy_cd68_vs_cd8 = spu.evaluate_classifier_tic(transformed_data, \"CD68 vs CD8\", n_runs)\n",
    "mean_accuracy_cd8_vs_foxp3 = spu.evaluate_classifier_tic(transformed_data, \"CD8 vs FoxP3\", n_runs)\n",
    "mean_accuracy_cd68_vs_foxp3 = spu.evaluate_classifier_tic(transformed_data, \"CD68 vs FoxP3\", n_runs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
